{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e9469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Tue Jul 24 09:55:10 2018\n",
    "\n",
    "@author: aguillenATC, jherrera\n",
    "\"\"\"\n",
    "#TOFIX :  para obtener el rendimieitno en test, hay que reentrenar con todo el cto de TRN y testear sobre TEST con los hiperparÃ¡metros optimos obtenidos!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167dcb1",
   "metadata": {
    "title": "INTRO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import keras.utils\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.metrics import  categorical_accuracy\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import initializers\n",
    "from keras import callbacks\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# Classifiers used\n",
    "from sklearn import neighbors\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "#from plot_conf_matrix import plot_conf_matrix\n",
    "\n",
    "from tools import calc_error_n_plot\n",
    "\n",
    "import time\n",
    "\n",
    "#####\n",
    "##### FOR DEBUGGING COMMENT THIS\n",
    "##Printing to a file\n",
    "import sys\n",
    "orig_stdout = sys.stdout\n",
    "bufsize = 10\n",
    "f = open('RESULTADOS_9_Mars_3vars.txt', 'w', buffering=bufsize)\n",
    "sys.stdout = f\n",
    "#sys.stdout = orig_stdout\n",
    "##MANERA ALTERNATIVA PARA PODER CONTROLAR LO QUE SE VA EJECUTANDO -->\n",
    "##f = open(filename,'w')\n",
    "##print >>f, 'whatever'     # Python 2.x\n",
    "##print('whatever', file=f) # Python 3.x\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "elapsed_t={}\n",
    "clasf_report={}\n",
    "prefijo=''\n",
    "path_datos=('../data'+prefijo+'/')\n",
    "path_results=('../results'+prefijo+'/')\n",
    "\n",
    "random_st=42\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "#X_df=pd.read_csv(path_datos+'XTrn.txt',usecols=['NALLParticlesTiotal','MUTotal','ELTotal','Zenith','Energy'])\n",
    "X_df=pd.read_csv(path_datos+'XTrn.txt',sep='  ',header=None)\n",
    "Y_df=pd.read_csv(path_datos+'YTrn.txt',sep='  ',header=None)\n",
    "X_test_df=pd.read_csv(path_datos+'XTest.txt',sep='  ',header=None)\n",
    "Y_test_df=pd.read_csv(path_datos+'YTest.txt',sep='  ',header=None)\n",
    "\n",
    "# CODE FOR 3 VARIABLES\n",
    "X_df=X_df[:][[2,1,4,0,3]]\n",
    "X_test_df =X_test_df[:][[2,1,4,0,3]]\n",
    "\n",
    "scalerX = StandardScaler()\n",
    "scalerX.fit(X_df)\n",
    "\n",
    "#scalerY = StandardScaler()\n",
    "#scalerY.fit(Y_df)\n",
    "\n",
    "X_train = scalerX.transform(X_df)\n",
    "Y_train = Y_df.values\n",
    "\n",
    "X_testYval_norm = scalerX.transform(X_test_df)\n",
    "\n",
    "X_TODO = np.concatenate((X_train,X_testYval_norm))\n",
    "Y_TODO = np.concatenate((Y_train,Y_test_df))\n",
    "#Y_norm = scalerY.transform(Y_df)\n",
    "#Y_test_norm = scalerY.transform(Y_test_df)\n",
    "\n",
    "#Test Val split\n",
    "\n",
    "X_test_norm,X_val,Y_test,Y_val=train_test_split(X_testYval_norm,\n",
    "                                            Y_test_df.values,\n",
    "                                            test_size=0.50,\n",
    "                                            random_state=45)\n",
    "\n",
    "#X_train=X_train[0:500]\n",
    "#Y_train=Y_train[0:500]\n",
    "\n",
    "n_folds=3\n",
    "k_fold = StratifiedKFold(n_splits=n_folds)\n",
    "\n",
    "n_foldsOUT=10\n",
    "k_foldOUT = StratifiedKFold(n_splits=n_foldsOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d35dd45",
   "metadata": {
    "title": "KNN"
   },
   "outputs": [],
   "source": [
    "\n",
    "print('\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"')\n",
    "print('KNN')\n",
    "print('\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa435a04",
   "metadata": {
    "title": "KNN"
   },
   "outputs": [],
   "source": [
    "start_t = time.time()\n",
    "\n",
    "#n_neighbors_list = list(range(1,30,1))\n",
    "n_neighbors_list = list(range(1,10  ,1))\n",
    "\n",
    "KNN_perf_record_test_CV = {}\n",
    "KNN_perf_record_train_CV = {}\n",
    "KNN_perf_record_test = {}\n",
    "KNN_perf_mean_record_train_CV = {}\n",
    "KNN_perf_mean_record_train_CV_std = {}\n",
    "KNN_perf_mean_record_test_CV = {}\n",
    "KNN_perf_mean_record_test_CV_std = {}\n",
    "\n",
    "\n",
    "for n_neighbors in n_neighbors_list:\n",
    "    fold=-1\n",
    "    for train_indices, test_indices in k_fold.split(X_train, Y_train):\n",
    "        fold+=1\n",
    "\n",
    "        start_time = time.time()\n",
    "        print('VAMOS por n_neighbour %d y por la fold %d / %d' % (n_neighbors,fold,n_folds))\n",
    "\n",
    "        #if n_neighbors not in KNN_perf_record_train_CV: KNN_perf_record_train_CV[n_neighbors] = np.zeros(n_folds)\n",
    "        if n_neighbors not in KNN_perf_record_test_CV: KNN_perf_record_test_CV[n_neighbors] = np.zeros(n_folds)\n",
    "\n",
    "        X_train_CV, X_test_CV = X_train[train_indices], X_train[test_indices]\n",
    "        Y_train_CV, Y_test_CV = Y_train[train_indices], Y_train[test_indices]\n",
    "\n",
    "        knn_clf = neighbors.KNeighborsClassifier(n_neighbors,metric='euclidean')\n",
    "        knn_clf.fit(X_train_CV, np.ravel(Y_train_CV))\n",
    "        #Y_pred_train_CV=knn_clf.predict(X_train_CV).reshape(-1,1)\n",
    "        #Y_pred_train_CV=Y_pred_train.reshape(-1,1)\n",
    "        Y_pred_test_CV=knn_clf.predict(X_test_CV).reshape(-1,1)\n",
    "        #Y_pred_test=knn_clf.predict(X_test_norm).reshape(-1,1)\n",
    "\n",
    "        #perf_record[fold][n_neighbors] = precision_recall_fscore_support(Y_test_CV,Y_pred_test_CV)\n",
    "        #KNN_perf_record_train_CV[n_neighbors][fold] = accuracy_score(Y_train_CV,Y_pred_train_CV)\n",
    "        KNN_perf_record_test_CV[n_neighbors][fold] = accuracy_score(Y_test_CV,Y_pred_test_CV)\n",
    "        #KNN_perf_record_test[n_neighbors][fold] = accuracy_score(Y_test,Y_pred_test)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        f.flush();\n",
    "\n",
    "    #if n_neighbors not in KNN_perf_mean_record_train_CV: KNN_perf_mean_record_train_CV[n_neighbors] = np.mean(KNN_perf_record_train_CV[n_neighbors])\n",
    "    #if n_neighbors not in KNN_perf_mean_record_train_CV_std: KNN_perf_mean_record_train_CV_std[n_neighbors] = np.std(KNN_perf_record_train_CV[n_neighbors])\n",
    "    if n_neighbors not in KNN_perf_mean_record_test_CV: KNN_perf_mean_record_test_CV[n_neighbors] = np.mean(KNN_perf_record_test_CV[n_neighbors])\n",
    "    if n_neighbors not in KNN_perf_mean_record_test_CV_std: KNN_perf_mean_record_test_CV_std[n_neighbors] = np.std(KNN_perf_record_test_CV[n_neighbors])\n",
    "#calc_error_n_plot(Y_train,Y_pred_train,'TRAIN')\n",
    "#clasf_report_val['KNN']=calc_error_n_plot(Y_val,Y_pred_val,'VALIDATION')\n",
    "#clasf_report['KNN']=calc_error_n_plot(Y_test,Y_pred_test,'TEST')\n",
    "\n",
    "elapsed_t['knn'] = time.time() - start_t\n",
    "best_indexKNN=list(KNN_perf_mean_record_test_CV.keys())[np.argmax(list(KNN_perf_mean_record_test_CV.values()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799fd01c",
   "metadata": {
    "title": "KNN"
   },
   "outputs": [],
   "source": [
    "\n",
    "KNN_perf_record_test = np.zeros(n_foldsOUT)\n",
    "KNN_perf_record_test_f1 = np.zeros(n_foldsOUT)\n",
    "\n",
    "fold=-1\n",
    "for train_indices, test_indices in k_foldOUT.split(X_TODO, Y_TODO):\n",
    "    fold+=1\n",
    "    X_train_CV2, X_test_CV2 = X_TODO[train_indices], X_TODO[test_indices]\n",
    "    Y_train_CV2, Y_test_CV2 = Y_TODO[train_indices], Y_TODO[test_indices]\n",
    "    knn_clf = neighbors.KNeighborsClassifier(best_indexKNN,metric='euclidean')\n",
    "    knn_clf.fit(X_train_CV2, np.ravel(Y_train_CV2))\n",
    "    Y_pred_test_CV2=knn_clf.predict(X_test_CV2).reshape(-1,1)\n",
    "    KNN_perf_record_test[fold] = accuracy_score(Y_test_CV2,Y_pred_test_CV2)\n",
    "    KNN_perf_record_test_f1[fold] = f1_score(Y_test_CV2,Y_pred_test_CV2, labels=np.array(range(5)), average='macro')\n",
    "\n",
    "\n",
    "#print('KNN - Best\\'s train CV accuracy %f (std= %f ) for n_neighbour %d \\n' % (np.max(list(KNN_perf_mean_record_train_CV.values())),KNN_perf_mean_record_train_CV_std[best_indexKNN],best_indexKNN))\n",
    "print('KNN - Best\\'s test CV accuracy %f (std= %f ) for n_neighbour %d \\n' % (np.max(list(KNN_perf_mean_record_test_CV.values())),KNN_perf_mean_record_test_CV_std[best_indexKNN],best_indexKNN))\n",
    "print('KNN - Test accuracy %s , mean: %f (std= %f) \\n' % (KNN_perf_record_test,np.mean(KNN_perf_record_test),np.std(KNN_perf_record_test)))\n",
    "print('KNN - Test f1_score %s , mean: %f (std= %f) \\n' % (KNN_perf_record_test_f1,np.mean(KNN_perf_record_test_f1),np.std(KNN_perf_record_test_f1)))\n",
    "print('Time elapsed for kNN %f' % elapsed_t['knn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabbb197",
   "metadata": {
    "title": "SVM"
   },
   "outputs": [],
   "source": [
    "print('\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"')\n",
    "print('SVM')\n",
    "print('\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751db56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_perf_record_train_CV = {}\n",
    "SVM_perf_record_test_CV = {}\n",
    "SVM_perf_record_test = {}\n",
    "SVM_perf_mean_record_test_CV = {}\n",
    "SVM_perf_mean_record_test_CV_std = {}\n",
    "SVM_perf_mean_record_train_CV = {}\n",
    "SVM_perf_mean_record_train_CV_std = {}\n",
    "\n",
    "start_t = time.time()\n",
    "\n",
    "exp_C=np.arange(-5,11,2)\n",
    "exp_gammas=np.arange(-15,0,2)\n",
    "\n",
    "C=np.exp2(exp_C)\n",
    "gammas=np.exp2(exp_gammas)\n",
    "\n",
    "config_listSVM=[]\n",
    "for i in C:\n",
    "    for j in gammas:\n",
    "        config_listSVM.append([i,j])\n",
    "\n",
    "config_idx=-1\n",
    "for config in config_listSVM:\n",
    "    config_idx+=1\n",
    "    fold=-1\n",
    "    for train_indices, test_indices in k_fold.split(X_train, Y_train):\n",
    "        fold+=1\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        #if config_idx not in SVM_perf_record_train_CV: SVM_perf_record_train_CV[config_idx] = np.zeros(n_folds)\n",
    "        if config_idx not in SVM_perf_record_test_CV: SVM_perf_record_test_CV[config_idx] = np.zeros(n_folds)\n",
    "        if config_idx not in SVM_perf_record_test: SVM_perf_record_test[config_idx] = np.zeros(n_folds)\n",
    "\n",
    "        X_train_CV, X_test_CV = X_train[train_indices], X_train[test_indices]\n",
    "        Y_train_CV, Y_test_CV = Y_train[train_indices], Y_train[test_indices]\n",
    "\n",
    "        clf = SVC(C=config[0],gamma=config[1])\n",
    "\n",
    "        clf.fit(X_train_CV, np.ravel(Y_train_CV))\n",
    "\n",
    "        #Y_pred_train_CV=clf.predict(X_train_CV).reshape(-1,1)\n",
    "        Y_pred_test_CV=clf.predict(X_test_CV).reshape(-1,1)\n",
    "        #Y_pred_test=clf.predict(X_test_norm).reshape(-1,1)\n",
    "\n",
    "        #SVM_perf_record_train_CV[config_idx][fold] = accuracy_score(Y_train_CV,Y_pred_train_CV)\n",
    "        SVM_perf_record_test_CV[config_idx][fold] = accuracy_score(Y_test_CV,Y_pred_test_CV)\n",
    "        #SVM_perf_record_test[config_idx][fold] = accuracy_score(Y_test,Y_pred_test)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        f.flush();\n",
    "\n",
    "    #if config_idx not in SVM_perf_mean_record_train_CV: SVM_perf_mean_record_train_CV[config_idx] = np.mean(SVM_perf_record_train_CV[config_idx])\n",
    "    #if config_idx not in SVM_perf_mean_record_train_CV_std: SVM_perf_mean_record_train_CV_std[config_idx] = np.std(SVM_perf_record_train_CV[config_idx])\n",
    "    if config_idx not in SVM_perf_mean_record_test_CV: SVM_perf_mean_record_test_CV[config_idx] = np.mean(SVM_perf_record_test_CV[config_idx])\n",
    "    if config_idx not in SVM_perf_mean_record_test_CV_std: SVM_perf_mean_record_test_CV_std[config_idx] = np.std(SVM_perf_record_test_CV[config_idx])\n",
    "\n",
    "elapsed_t['SVM'] = time.time() - start_t\n",
    "\n",
    "#calc_error_n_plot(Y_train,Y_pred_train,'TRAIN')\n",
    "#calc_error_n_plot(Y_val,Y_pred_val,'VALIDATION')\n",
    "#clasf_report['SVM']=calc_error_n_plot(Y_test,Y_pred_test,'TEST')\n",
    "best_indexSVM=list(SVM_perf_mean_record_test_CV.keys())[np.argmax(list(SVM_perf_mean_record_test_CV.values()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3810e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_listSVM[best_indexSVM]\n",
    "SVM_perf_record_test = np.zeros(n_foldsOUT)\n",
    "SVM_perf_record_test_f1 = np.zeros(n_foldsOUT)\n",
    "fold=-1\n",
    "for train_indices, test_indices in k_foldOUT.split(X_TODO, Y_TODO):\n",
    "    fold+=1\n",
    "    X_train_CV2, X_test_CV2 = X_TODO[train_indices], X_TODO[test_indices]\n",
    "    Y_train_CV2, Y_test_CV2 = Y_TODO[train_indices], Y_TODO[test_indices]\n",
    "    clf = SVC(C=config[0],gamma=config[1])\n",
    "    clf.fit(X_train_CV2, np.ravel(Y_train_CV2))\n",
    "    Y_pred_test_CV2=clf.predict(X_test_CV2).reshape(-1,1)\n",
    "    SVM_perf_record_test_f1[fold] = f1_score(Y_test_CV2,Y_pred_test_CV2, labels=np.array(range(5)), average='macro')\n",
    "    SVM_perf_record_test[fold] = accuracy_score(Y_test_CV2,Y_pred_test_CV2)\n",
    "\n",
    "#print('SVM - Best\\'s train CV accuracy %f (std= %f ) for config %s \\n' % (np.max(list(SVM_perf_mean_record_train_CV.values())),SVM_perf_mean_record_train_CV_std[best_indexSVM],config_listSVM[best_indexSVM]))\n",
    "print('SVM - Best\\'s test CV accuracy %f (std= %f ) for config %s \\n' % (np.max(list(SVM_perf_mean_record_test_CV.values())),SVM_perf_mean_record_test_CV_std[best_indexSVM],config_listSVM[best_indexSVM]))\n",
    "print('SVM - Best\\'s Test accuracy %s , mean: %f (std= %f) \\n' % (SVM_perf_record_test,np.mean(SVM_perf_record_test),np.std(SVM_perf_record_test)))\n",
    "print('SVM - Test f1_score %s , mean: %f (std= %f) \\n' % (SVM_perf_record_test_f1,np.mean(SVM_perf_record_test_f1),np.std(SVM_perf_record_test_f1)))\n",
    "print('Time elapsed for SVM %f' % elapsed_t['SVM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16104174",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "XGBOOST"
   },
   "outputs": [],
   "source": [
    "print('\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"')\n",
    "print('XGBoost')\n",
    "print('\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a007fbdb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "XGBoost\n",
    "https://xgboost.ai/about\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "XGB_perf_record_train_CV = {}\n",
    "XGB_perf_record_test_CV = {}\n",
    "XGB_perf_record_test = {}\n",
    "XGB_perf_mean_record_test_CV = {}\n",
    "XGB_perf_mean_record_test_CV_std = {}\n",
    "XGB_perf_mean_record_train_CV = {}\n",
    "XGB_perf_mean_record_train_CV_std = {}\n",
    "\n",
    "start_t = time.time()\n",
    "\n",
    "max_depth_list=np.arange(3,6,1)\n",
    "eta_list=np.arange(0.05,1,0.05)\n",
    "\n",
    "config_listXGB=[]\n",
    "for i in max_depth_list:\n",
    "    for j in eta_list:\n",
    "        config_listXGB.append([i,j])\n",
    "\n",
    "#dtrain = xgb.DMatrix(np.concatenate((X_train,Y_train),axis=1))\n",
    "#dtest = xgb.DMatrix(np.concatenate((X_test_norm,Y_test_df.values),axis=1))\n",
    "\n",
    "#dtrain = xgb.DMatrix(X_train, label=Y_train)\n",
    "#dtest = xgb.DMatrix(X_test_norm,label=Y_test)\n",
    "\n",
    "config_idx=-1\n",
    "for config in config_listXGB:\n",
    "    config_idx+=1\n",
    "    fold=-1\n",
    "    for train_indices, test_indices in k_fold.split(X_train, Y_train):\n",
    "        fold+=1\n",
    "\n",
    "        start_time = time.time()\n",
    "        #print('VAMOS por config %d: %d , %.3f y por la fold %d / %d' % (config_idx, config[0],config[1],fold,n_folds))\n",
    "\n",
    "        #if config_idx not in XGB_perf_record_train_CV: XGB_perf_record_train_CV[config_idx] = np.zeros(n_folds)\n",
    "        if config_idx not in XGB_perf_record_test_CV: XGB_perf_record_test_CV[config_idx] = np.zeros(n_folds)\n",
    "        if config_idx not in XGB_perf_record_test: XGB_perf_record_test[config_idx] = np.zeros(n_folds)\n",
    "\n",
    "        X_train_CV, X_test_CV = X_train[train_indices], X_train[test_indices]\n",
    "        Y_train_CV, Y_test_CV = Y_train[train_indices], Y_train[test_indices]\n",
    "\n",
    "        dtrain_CV = xgb.DMatrix(X_train_CV, label=Y_train_CV)\n",
    "        dtest_CV = xgb.DMatrix(X_test_CV,label=Y_test_CV)\n",
    "        dtest = xgb.DMatrix(X_test_norm,label=Y_test)\n",
    "\n",
    "        # specify parameters via map\n",
    "        param = {'max_depth':config[0], 'eta':config[1], 'silent':1, 'objective':'multi:softmax', 'num_class':5 }#, 'nthread': 4} el nthread no hace lo esperado de dividir por nucleos\n",
    "        num_round = 150\n",
    "        bst = xgb.train(param, dtrain_CV, num_round)\n",
    "        # make prediction\n",
    "        #Y_pred_test = bst.predict(dtest)\n",
    "\n",
    "        #Y_pred_train_CV=bst.predict(dtrain_CV)\n",
    "        Y_pred_test_CV=bst.predict(dtest_CV)\n",
    "        #Y_pred_test=bst.predict(dtest)\n",
    "\n",
    "        #XGB_perf_record_train_CV[config_idx][fold] = accuracy_score(Y_train_CV,Y_pred_train_CV)\n",
    "        XGB_perf_record_test_CV[config_idx][fold] = accuracy_score(Y_test_CV,Y_pred_test_CV)\n",
    "        #XGB_perf_record_test[config_idx][fold] = accuracy_score(Y_test,Y_pred_test)\n",
    "\n",
    "        print(\"--- %s seconds ---  testcv: %s test: %s\" % ((time.time() - start_time), XGB_perf_record_test_CV[config_idx][fold], XGB_perf_record_test[config_idx][fold]))\n",
    "        f.flush();\n",
    "\n",
    "    #if config_idx not in XGB_perf_mean_record_train_CV: XGB_perf_mean_record_train_CV[config_idx] = np.mean(XGB_perf_record_train_CV[config_idx])\n",
    "    #if config_idx not in XGB_perf_mean_record_train_CV_std: XGB_perf_mean_record_train_CV_std[config_idx] = np.std(XGB_perf_record_train_CV[config_idx])\n",
    "    if config_idx not in XGB_perf_mean_record_test_CV: XGB_perf_mean_record_test_CV[config_idx] = np.mean(XGB_perf_record_test_CV[config_idx])\n",
    "    if config_idx not in XGB_perf_mean_record_test_CV_std: XGB_perf_mean_record_test_CV_std[config_idx] = np.std(XGB_perf_record_test_CV[config_idx])\n",
    "\n",
    "elapsed_t['XGB'] = time.time() - start_t\n",
    "\n",
    "best_indexXGB=list(XGB_perf_mean_record_test_CV.keys())[np.argmax(list(XGB_perf_mean_record_test_CV.values()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c597fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_listXGB[best_indexXGB]\n",
    "XGB_perf_record_test = np.zeros(n_foldsOUT)\n",
    "XGB_perf_record_test_f1 = np.zeros(n_foldsOUT)\n",
    "\n",
    "fold=-1\n",
    "for train_indices, test_indices in k_foldOUT.split(X_TODO, Y_TODO):\n",
    "    fold+=1\n",
    "    X_train_CV2, X_test_CV2 = X_TODO[train_indices], X_TODO[test_indices]\n",
    "    Y_train_CV2, Y_test_CV2 = Y_TODO[train_indices], Y_TODO[test_indices]\n",
    "    dtrain_CV = xgb.DMatrix(X_train_CV2, label=Y_train_CV2)\n",
    "    dtest = xgb.DMatrix(X_test_CV2,label=Y_test_CV2)\n",
    "\n",
    "    # specify parameters via map\n",
    "    param = {'max_depth':config[0], 'eta':config[1], 'silent':1, 'objective':'multi:softmax', 'num_class':5 }#, 'nthread': 4} el nthread no hace lo esperado de dividir por nucleos\n",
    "    num_round = 150\n",
    "    bst = xgb.train(param, dtrain_CV, num_round)\n",
    "    Y_pred_test_CV2=bst.predict(dtest)\n",
    "    XGB_perf_record_test_f1[fold] = f1_score(Y_test_CV2,Y_pred_test_CV2, labels=np.array(range(5)), average='macro')\n",
    "    XGB_perf_record_test[fold] = accuracy_score(Y_test_CV2,Y_pred_test_CV2)\n",
    "\n",
    "#print('XGB - Best\\'s train CV accuracy %f (std= %f ) for config %s \\n' % (np.max(list(XGB_perf_mean_record_train_CV.values())),XGB_perf_mean_record_train_CV_std[best_indexXGB],config_listXGB[best_indexXGB]))\n",
    "print('XGB - Best\\'s test CV accuracy %f (std= %f ) for config %s \\n' % (np.max(list(XGB_perf_mean_record_test_CV.values())),XGB_perf_mean_record_test_CV_std[best_indexXGB],config_listXGB[best_indexXGB]))\n",
    "print('XGB - Best\\'s Test accuracy %s , mean: %f (std= %f) \\n' % (XGB_perf_record_test,np.mean(XGB_perf_record_test),np.std(XGB_perf_record_test)))\n",
    "print('XGB - Test f1_score %s , mean: %f (std= %f) \\n' % (XGB_perf_record_test_f1,np.mean(XGB_perf_record_test_f1),np.std(XGB_perf_record_test_f1)))\n",
    "print('Time elapsed for XGB %f' % elapsed_t['XGB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4044c786",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "DNNs"
   },
   "outputs": [],
   "source": [
    "\n",
    "#TOFIX probar los DNNs y ver lo q tarda, decidir etc\n",
    "print('\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"')\n",
    "print('DNN')\n",
    "print('\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d365702",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def clasif_model(individual):\n",
    "\n",
    "    activation_functions={\n",
    "        0:\"relu\",\n",
    "        1:\"sigmoid\",\n",
    "        2:\"softmax\",\n",
    "        3:\"tanh\",\n",
    "        4:\"selu\",\n",
    "        5:\"softplus\",\n",
    "        6:\"softsign\",\n",
    "        7:\"linear\"\n",
    "    }\n",
    "\n",
    "    dimension=3\n",
    "    model = Sequential()\n",
    "    for units,activ_f in individual:\n",
    "       if(units>5):\n",
    "           model.add(Dense(units=units, input_dim=dimension, kernel_initializer=initializers.Constant(value=0.025), activation=activation_functions[activ_f]))\n",
    "\n",
    "    model.add(Dense(units=5, activation=\"softmax\", kernel_initializer=initializers.Constant(value=0.025)))\n",
    "\n",
    "    #SGD(lr=0.05, momentum=0.1, decay=0.001, nesterov=False)\n",
    "    #model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "    #Adam(lr=0.1, beta_1=0.09, beta_2=0.999, epsilon=1e-08, decay=0.0) #adam defaults Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    #Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0) # Adan defaults\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68fcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DNN_perf_record_train_CV = {}\n",
    "DNN_perf_record_test_CV = {}\n",
    "DNN_perf_record_test = {}\n",
    "DNN_perf_mean_record_test_CV = {}\n",
    "DNN_perf_mean_record_test_CV_std = {}\n",
    "DNN_perf_mean_record_train_CV = {}\n",
    "DNN_perf_mean_record_train_CV_std = {}\n",
    "\n",
    "start_t = time.time()\n",
    "\n",
    "max_individuals=64\n",
    "max_depth=6\n",
    "individuals={}\n",
    "for i in range(0,max_individuals):\n",
    "    individuals[i]=[]\n",
    "    layers=int(np.round(np.random.rand(1)*(max_depth -1) +1)+1)\n",
    "    units=np.ceil(np.random.rand(1,layers)*45 +5)[0]\n",
    "    act_func=np.zeros((1,layers))[0];#np.ceil(np.random.rand(1,layers)*7)[0]\n",
    "    for j in range(0,layers):\n",
    "        individuals[i].append((units[j],act_func[j]))\n",
    "\n",
    "batch_size_list=np.array([128])#256,512,1024])\n",
    "\n",
    "config_listDNN=[]\n",
    "for i in range(0,max_individuals):\n",
    "    for j in batch_size_list:\n",
    "        config_listDNN.append([individuals[i],j])\n",
    "\n",
    "config_idx=-1\n",
    "for config in config_listDNN:\n",
    "    config_idx+=1\n",
    "    fold=-1\n",
    "    for train_indices, test_indices in k_fold.split(X_train, Y_train):\n",
    "        fold+=1\n",
    "\n",
    "        start_time = time.time()\n",
    "        #print('VAMOS por config %d: %s , %.3f y por la fold %d / %d' % (config_idx, config[0],config[1],fold,n_folds))\n",
    "\n",
    "        #if config_idx not in DNN_perf_record_train_CV: DNN_perf_record_train_CV[config_idx] = np.zeros(n_folds)\n",
    "        if config_idx not in DNN_perf_record_test_CV: DNN_perf_record_test_CV[config_idx] = np.zeros(n_folds)\n",
    "        if config_idx not in DNN_perf_record_test: DNN_perf_record_test[config_idx] = np.zeros(n_folds)\n",
    "\n",
    "        X_train_CV, X_test_CV = X_train[train_indices], X_train[test_indices]\n",
    "        Y_train_CV, Y_test_CV = Y_train[train_indices], Y_train[test_indices]\n",
    "\n",
    "        #Prepare one hot encoding...\n",
    "        hot_Y_train_CV = keras.utils.to_categorical(Y_train_CV,num_classes=5)\n",
    "        #hot_Y_val = keras.utils.to_categorical(Y_val,num_classes=5)\n",
    "        hot_Y_test_CV = keras.utils.to_categorical(Y_test_CV,num_classes=5)\n",
    "        hot_Y_test = keras.utils.to_categorical(Y_test,num_classes=5)\n",
    "\n",
    "        DNN = KerasRegressor(build_fn=clasif_model, individual=config[0], verbose=0)\n",
    "        early_stopping=callbacks.EarlyStopping(monitor='loss', min_delta=1e-03, patience=20, verbose=1, mode='min')\n",
    "        reduce_lr = callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1,patience=10, min_lr=0.001, min_delta=1e-03, verbose=1)\n",
    "        callback_list=[early_stopping, reduce_lr]\n",
    "        DNN.fit(X_train_CV,hot_Y_train_CV, epochs=300, batch_size=config[1],callbacks=callback_list)#, validation_data=(X_val,hot_Y_val))\n",
    "\n",
    "        #Y_pred_train_CV=DNN.predict(X_train_CV)\n",
    "        Y_pred_test_CV=DNN.predict(X_test_CV)\n",
    "        #Y_pred_test=DNN.predict(X_test_norm)\n",
    "\n",
    "        #hot_Y_pred_train_CV = keras.utils.to_categorical(np.argmax(Y_pred_train_CV, axis = 1),num_classes=5)\n",
    "        hot_Y_pred_test_CV = keras.utils.to_categorical(np.argmax(Y_pred_test_CV, axis = 1),num_classes=5)\n",
    "        #hot_Y_pred_test = keras.utils.to_categorical(np.argmax(Y_pred_test, axis = 1),num_classes=5)\n",
    "\n",
    "        #DNN_perf_record_train_CV[config_idx][fold] = accuracy_score(hot_Y_train_CV,hot_Y_pred_train_CV)\n",
    "        DNN_perf_record_test_CV[config_idx][fold] = accuracy_score(hot_Y_test_CV,hot_Y_pred_test_CV)\n",
    "        #DNN_perf_record_test[config_idx][fold] = accuracy_score(hot_Y_test,hot_Y_pred_test)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        f.flush();\n",
    "\n",
    "    #if config_idx not in DNN_perf_mean_record_train_CV: DNN_perf_mean_record_train_CV[config_idx] = np.mean(DNN_perf_record_train_CV[config_idx])\n",
    "    #if config_idx not in DNN_perf_mean_record_train_CV_std: DNN_perf_mean_record_train_CV_std[config_idx] = np.std(DNN_perf_record_train_CV[config_idx])\n",
    "    if config_idx not in DNN_perf_mean_record_test_CV: DNN_perf_mean_record_test_CV[config_idx] = np.mean(DNN_perf_record_test_CV[config_idx])\n",
    "    if config_idx not in DNN_perf_mean_record_test_CV_std: DNN_perf_mean_record_test_CV_std[config_idx] = np.std(DNN_perf_record_test_CV[config_idx])\n",
    "\n",
    "elapsed_t['DNN'] = time.time() - start_t\n",
    "\n",
    "best_indexDNN=list(DNN_perf_mean_record_test_CV.keys())[np.argmax(list(DNN_perf_mean_record_test_CV.values()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28275f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_listDNN[best_indexDNN]\n",
    "DNN_perf_record_test = np.zeros(n_foldsOUT)\n",
    "DNN_perf_record_test_f1 = np.zeros(n_foldsOUT)\n",
    "fold=-1\n",
    "for train_indices, test_indices in k_foldOUT.split(X_TODO, Y_TODO):\n",
    "    fold+=1\n",
    "    X_train_CV2, X_test_CV2 = X_TODO[train_indices], X_TODO[test_indices]\n",
    "    Y_train_CV2, Y_test_CV2 = Y_TODO[train_indices], Y_TODO[test_indices]\n",
    "\n",
    "    #Prepare one hot encoding...\n",
    "    hot_Y_train_CV2 = keras.utils.to_categorical(Y_train_CV2,num_classes=5)\n",
    "    hot_Y_test_CV2  = keras.utils.to_categorical(Y_test_CV2,num_classes=5)\n",
    "\n",
    "    DNN = KerasRegressor(build_fn=clasif_model, individual=config[0], verbose=0)\n",
    "    early_stopping=callbacks.EarlyStopping(monitor='loss', min_delta=1e-03, patience=20, verbose=1, mode='min')\n",
    "    reduce_lr = callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1,patience=10, min_lr=0.001, min_delta=1e-03, verbose=1)\n",
    "    callback_list=[early_stopping, reduce_lr]\n",
    "    DNN.fit(X_train_CV2,hot_Y_train_CV2, epochs=300, batch_size=config[1],callbacks=callback_list)#, validation_data=(X_val,hot_Y_val))\n",
    "\n",
    "    Y_pred_test_CV2=DNN.predict(X_test_CV2)\n",
    "    hot_Y_pred_test_CV2 = keras.utils.to_categorical(np.argmax(Y_pred_test_CV2, axis = 1),num_classes=5)\n",
    "    DNN_perf_record_test_f1[fold] = f1_score(hot_Y_test_CV2,hot_Y_pred_test_CV2, labels=np.array(range(5)), average='macro')\n",
    "    DNN_perf_record_test[fold] = accuracy_score(hot_Y_test_CV2,hot_Y_pred_test_CV2)\n",
    "\n",
    "#print('DNN - Best\\'s train CV accuracy %f (std= %f ) for config %s \\n' % (np.max(list(DNN_perf_mean_record_train_CV.values())),DNN_perf_mean_record_train_CV_std[best_indexDNN],config_listDNN[best_indexDNN]))\n",
    "print('DNN - Best\\'s test CV accuracy %f (std= %f ) for config %s \\n' % (np.max(list(DNN_perf_mean_record_test_CV.values())),DNN_perf_mean_record_test_CV_std[best_indexDNN],config_listDNN[best_indexDNN]))\n",
    "print('DNN - Best\\'s Test accuracy %s , mean: %f (std= %f) \\n' % (DNN_perf_record_test,np.mean(DNN_perf_record_test),np.std(DNN_perf_record_test)))\n",
    "print('DNN - Test f1_score %s , mean: %f (std= %f) \\n' % (DNN_perf_record_test_f1,np.mean(DNN_perf_record_test_f1),np.std(DNN_perf_record_test_f1)))\n",
    "print('Time elapsed for DNN %f' % elapsed_t['DNN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baa277d",
   "metadata": {
    "title": "REPORT"
   },
   "outputs": [],
   "source": [
    "print('\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"')\n",
    "print('\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"REPORT\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"')\n",
    "print('\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"')\n",
    "#print('KNN - Best\\'s train CV accuracy %f (std= %f ) for n_neighbour %d \\n' % (np.max(list(KNN_perf_mean_record_train_CV.values())),KNN_perf_mean_record_train_CV_std[best_indexKNN],best_indexKNN))\n",
    "print('KNN - Best\\'s test CV accuracy %f (std= %f ) for n_neighbour %d \\n' % (np.max(list(KNN_perf_mean_record_test_CV.values())),KNN_perf_mean_record_test_CV_std[best_indexKNN],best_indexKNN))\n",
    "print('KNN - Test accuracy %s , mean: %f (std= %f) \\n' % (KNN_perf_record_test[best_indexKNN],np.mean(KNN_perf_record_test[best_indexKNN]),np.std(KNN_perf_record_test[best_indexKNN])))\n",
    "print('Time elapsed for kNN %f' % elapsed_t['knn'])\n",
    "#print('SVM - Best\\'s train CV accuracy %f (std= %f ) for config %s \\n' % (np.max(list(SVM_perf_mean_record_train_CV.values())),SVM_perf_mean_record_train_CV_std[best_indexSVM],config_listSVM[best_indexSVM]))\n",
    "print('SVM - Best\\'s test CV accuracy %f (std= %f ) for config %s \\n' % (np.max(list(SVM_perf_mean_record_test_CV.values())),SVM_perf_mean_record_test_CV_std[best_indexSVM],config_listSVM[best_indexSVM]))\n",
    "print('SVM - Best\\'s Test accuracy %s , mean: %f (std= %f) \\n' % (SVM_perf_record_test[best_indexSVM],np.mean(SVM_perf_record_test[best_indexSVM]),np.std(SVM_perf_record_test[best_indexSVM])))\n",
    "print('Time elapsed for SVM %f' % elapsed_t['SVM'])\n",
    "#print('XGB - Best\\'s train CV accuracy %f (std= %f ) for config %s \\n' % (np.max(list(XGB_perf_mean_record_train_CV.values())),XGB_perf_mean_record_train_CV_std[best_indexXGB],config_listXGB[best_indexXGB]))\n",
    "print('XGB - Best\\'s test CV accuracy %f (std= %f ) for config %s \\n' % (np.max(list(XGB_perf_mean_record_test_CV.values())),XGB_perf_mean_record_test_CV_std[best_indexXGB],config_listXGB[best_indexXGB]))\n",
    "print('XGB - Best\\'s Test accuracy %s , mean: %f (std= %f) \\n' % (XGB_perf_record_test[best_indexXGB],np.mean(XGB_perf_record_test[best_indexXGB]),np.std(XGB_perf_record_test[best_indexXGB])))\n",
    "print('Time elapsed for XGB %f' % elapsed_t['XGB'])\n",
    "#print('DNN - Best\\'s train CV accuracy %f (std= %f ) for config %s \\n' % (np.max(list(DNN_perf_mean_record_train_CV.values())),DNN_perf_mean_record_train_CV_std[best_indexDNN],config_listDNN[best_indexDNN]))\n",
    "print('DNN - Best\\'s test CV accuracy %f (std= %f ) for config %s \\n' % (np.max(list(DNN_perf_mean_record_test_CV.values())),DNN_perf_mean_record_test_CV_std[best_indexDNN],config_listDNN[best_indexDNN]))\n",
    "print('DNN - Best\\'s Test accuracy %s , mean: %f (std= %f) \\n' % (DNN_perf_record_test[best_indexDNN],np.mean(DNN_perf_record_test[best_indexDNN]),np.std(DNN_perf_record_test[best_indexDNN])))\n",
    "print('Time elapsed for DNN %f' % elapsed_t['DNN'])\n",
    "sys.stdout = orig_stdout\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
